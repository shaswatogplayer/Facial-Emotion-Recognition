## Facial Emotion Recognition with Deep Learning
# Overview
This project implements a Facial Emotion Recognition (FER) system that dynamically captures facial emotions and determines the most dominant emotional trait. Using Deep Learning techniques, this model achieves high accuracy by leveraging state-of-the-art architectures and libraries. A user-friendly interface is built using Streamlit, making it interactive and easy to use.

# Key Highlights

Accuracy: Achieved 98.3% accuracy using the CK+ dataset.

Deep Learning Architectures: Compared the performance of models such as VGG-19, ResNet-50, and InceptionV3.

Dynamic Emotion Detection: Captures live video streams using OpenCV and provides real-time emotion predictions.

Interactive UI: Built with Streamlit, allowing users to test the system directly in a web-based interface.

Technologies and Tools Used

Programming Language: Python

# Libraries:
Deep Learning: TensorFlow, Keras

Computer Vision: OpenCV

UI Development: Streamlit

Deep Learning Architectures:

VGG-19: Achieved the highest accuracy (98.3%)

ResNet-50

InceptionV3

Dataset: CK+ (Extended Cohn-Kanade Dataset)

# Features
Real-Time Emotion Detection:

Processes video frames dynamically using OpenCV.

Identifies and displays the most dominant emotion in real time.

Model Comparison:

Analyzes the performance of multiple deep learning models, including VGG-19, ResNet-50, and InceptionV3.

Results are benchmarked for accuracy and performance.

# High Accuracy:

Achieved 98.3% accuracy using VGG-19 with the CK+ dataset.

# Streamlit Interface:

User-friendly and interactive web-based UI.

Upload static images or activate the live webcam for emotion detection.

Emotion Classes:

Recognizes multiple emotional states such as Anger, Happiness, Sadness, Fear, Disgust, Surprise, and Neutral.
